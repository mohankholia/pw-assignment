{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a557df1-3a81-4bf7-9efc-0301d04227ce",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Q9. Provide an example of a classification problem where recall is the most important metric, and explain why.\n",
    "In a medical diagnosis scenario, where missing a positive case (false negative) can have severe consequences, recall becomes important to minimize false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90ba53-a81a-4fe3-9ef9-0fce712885d5",
   "metadata": {},
   "source": [
    "## Q1. Describe the decision tree classifier algorithm and how it works to make predictions.\n",
    "The decision tree classifier algorithm is a supervised learning algorithm used for both classification and regression tasks. It works by recursively partitioning the input space into regions, assigning a class label to each region. The decision-making process involves binary splits based on features, leading to a tree-like structure where each internal node represents a decision based on a feature, and each leaf node represents the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2773c4-ac0a-4f17-b363-0ebce78ec7a3",
   "metadata": {},
   "source": [
    "## Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.\n",
    "Decision trees use metrics like information gain or Gini impurity to determine the best split at each node.\n",
    "Information gain measures the reduction in uncertainty about class labels after a split.\n",
    "Gini impurity measures the probability of misclassifying a randomly chosen element.\n",
    "The algorithm selects the feature and split point that maximize information gain or minimize Gini impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9479baa-da20-462d-950d-8b64afc90892",
   "metadata": {},
   "source": [
    "## Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.\n",
    "For binary classification, the tree recursively splits the data into subsets based on feature values.\n",
    "Each internal node represents a decision based on a feature, and each leaf node represents the predicted class.\n",
    "The process continues until a stopping criterion is met (e.g., maximum depth, minimum samples per leaf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca217c48-7c54-48de-9d8d-2f40c57520cd",
   "metadata": {},
   "source": [
    "## Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions.\n",
    "Decision tree boundaries in feature space are orthogonal to the axes, creating axis-aligned splits.\n",
    "At each node, the algorithm selects the feature and threshold that best separates the data into distinct regions.\n",
    "The hierarchical structure of the tree forms nested decision regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24e355-c9d0-4e27-82b7-86f0e4f383ab",
   "metadata": {},
   "source": [
    "## Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model.\n",
    "A confusion matrix is a table summarizing the performance of a classification model, with entries like true positive (TP), true negative (TN), false positive (FP), and false negative (FN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7d7fd-fa46-4782-ade3-c23a7098a5e5",
   "metadata": {},
   "source": [
    "\n",
    "## Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it.\n",
    "Actual\\Predicted | Positive | Negative\n",
    "-----------------|----------|----------\n",
    "Positive         | 120      | 20\n",
    "Negative         | 10       | 150\n",
    "Precision = TP / (TP + FP) = 120 / (120 + 20) = 0.857\n",
    "Recall = TP / (TP + FN) = 120 / (120 + 10) = 0.923\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.857 * 0.923) / (0.857 + 0.923) = 0.888"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a401d2-04e1-41c5-a0db-27204cc619ac",
   "metadata": {},
   "source": [
    "## Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done.\n",
    "The choice depends on the problem and goals. For imbalanced datasets, accuracy might be misleading.\n",
    "Precision, recall, F1 score, and area under the ROC curve are useful alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12891c9a-96d5-4f48-8511-8bed7bcede31",
   "metadata": {},
   "source": [
    "## Q8. Provide an example of a classification problem where precision is the most important metric, and explain why.\n",
    "In email spam detection, where marking a legitimate email as spam (false positive) is more critical, precision is crucial to minimize false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06300ec-97f0-4b74-ae1c-e098fdd7e451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
